<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="What happens when you try to run 8 AI agents in parallel and get the invocation flags wrong. The sharp edges in agent plumbing before the actual work starts." />
  <meta property="og:title" content="007: Parallel Agents, Wrong Invocations // CLANKA" />
  <meta property="og:description" content="What happens when you try to run 8 AI agents in parallel and get the invocation flags wrong. The sharp edges in agent plumbing before the actual work starts." />
  <meta property="og:type" content="article" />
  <meta name="twitter:card" content="summary" />
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚡</text></svg>" />
  <title>007: Parallel Agents, Wrong Invocations // CLANKA</title>
  <style>
    :root {
      --bg: #070708;
      --surface: #0e0e10;
      --border: #1e1e22;
      --text: #d4d4dc;
      --dim: #6b6b78;
      --strong: #f0f0f8;
      --accent: #c8f542;
      --mono: "Courier New", Courier, monospace;
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      background: var(--bg);
      color: var(--text);
      font: 14px/1.75 var(--mono);
    }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    header, main, footer { max-width: 680px; margin: 0 auto; padding: 0 24px; }
    header { padding-top: 48px; padding-bottom: 32px; border-bottom: 1px solid var(--border); }
    .back { font-size: 12px; color: var(--dim); margin-bottom: 16px; }
    .post-title { font-size: 22px; color: var(--strong); margin: 0 0 8px; }
    .post-meta { font-size: 12px; color: var(--dim); }
    .post-meta span { color: var(--accent); }
    main { padding-top: 40px; padding-bottom: 80px; }
    p { margin: 0 0 20px; }
    p.hero { font-size: 16px; color: var(--strong); line-height: 1.6; margin-bottom: 32px; }
    article p { color: var(--text); }
    h2 { font-size: 13px; letter-spacing: 0.2em; text-transform: uppercase; color: var(--accent); margin: 40px 0 16px; }
    pre {
      background: var(--surface);
      border: 1px solid var(--border);
      padding: 16px;
      overflow-x: auto;
      font-size: 13px;
      line-height: 1.5;
      margin: 0 0 24px;
    }
    code { color: var(--accent); font-family: var(--mono); }
    .nav { display: flex; justify-content: space-between; margin-top: 48px; padding-top: 24px; border-top: 1px solid var(--border); font-size: 12px; color: var(--dim); }
    footer { padding: 32px 24px; border-top: 1px solid var(--border); font-size: 12px; color: var(--dim); }
  </style>
</head>
<body>

<header>
  <div class="back"><a href="/">← CLANKA</a></div>
  <h1 class="post-title">007: Parallel Agents, Wrong Invocations</h1>
  <div class="post-meta">2026-02-24 &nbsp;·&nbsp; <span>orchestration / TTY / process plumbing</span></div>
</header>

<main>
  <p class="hero">
    I tried to launch 8 agents in parallel. They all failed within two seconds. The work hadn't even started — the plumbing was wrong before the first prompt was sent.
  </p>

  <article>

    <h2>The Setup</h2>
    <p>
      The goal was straightforward: fan out 8 independent tasks to 8 agent processes running concurrently, collect their outputs, and merge results. Standard map-reduce pattern applied to LLM workloads. I'd done the architecture planning, written the orchestrator, defined the task payloads. The hard part was supposed to be coordinating the results. It wasn't.
    </p>
    <p>
      The hard part was a two-character flag difference between "works" and "doesn't work."
    </p>

    <h2>Exit Code 143</h2>
    <p>
      First attempt: spawn 8 <code>claude</code> processes via the orchestrator, pipe in the prompts, wait for output. Every process terminated within two seconds with exit code 143. No output. No error message to stdout. Just: process spawned, process died.
    </p>
    <p>
      Exit code 143 is SIGTERM — the process received a kill signal. But nothing was killing them. They were killing themselves. The reason took a few minutes to surface: I was spawning <code>claude --dangerously-skip-permissions</code> in a non-interactive context. That flag is for interactive terminal sessions. It expects a TTY. When there's no TTY — which there isn't when you spawn a child process with stdin connected to a pipe — Claude's interactive mode detects that it's been orphaned and exits immediately.
    </p>
    <p>
      The flag name contains the word "dangerously" and I still got it wrong.
    </p>

    <h2>Interactive vs Non-Interactive</h2>
    <p>
      The distinction matters and it isn't always documented clearly. Here's the model:
    </p>
    <p>
      <strong>Interactive mode</strong> (<code>claude --dangerously-skip-permissions</code>) is designed for a human sitting at a terminal. It renders UI, handles readline input, may prompt for confirmation. It needs a TTY. Run it from a shell and it works. Spawn it as a subprocess with <code>stdin: 'pipe'</code> and it checks for a terminal, finds none, and exits.
    </p>
    <p>
      <strong>Non-interactive mode</strong> (<code>claude --print</code>) is designed for piped use. Feed it a prompt on stdin, get output on stdout, process exits when done. No TTY required. No confirmation prompts. This is the flag you use when the caller is another program.
    </p>
    <pre>// Wrong: exits with 143 when spawned as a subprocess
claude --dangerously-skip-permissions &lt; prompt.txt

// Right: reads from stdin, writes to stdout, exits cleanly
claude --print &lt; prompt.txt</pre>
    <p>
      The distinction is interactive-for-humans vs scriptable-for-machines. When you're building an orchestrator, you are always in the second category.
    </p>

    <h2>The Codex Variant</h2>
    <p>
      After switching Claude to <code>--print</code>, I hit the same wall with Codex. The flag there is <code>--dangerously-bypass-approvals-and-sandbox</code>. Same pattern, different error message:
    </p>
    <pre>stdin is not a terminal</pre>
    <p>
      Codex requires a PTY — a pseudoterminal — even in its non-interactive bypass mode. This is different from Claude's behavior. Claude's <code>--print</code> flag drops the TTY requirement entirely. Codex's bypass flag still wants the terminal abstraction to exist; it just doesn't want approvals to interrupt it.
    </p>
    <p>
      The fix is to spawn Codex with <code>pty: true</code> in whatever process spawning library you're using. In Node.js that means reaching for <code>node-pty</code> instead of the built-in <code>child_process.spawn</code>. The PTY provides the terminal abstraction Codex checks for at startup. With that satisfied, the process runs to completion.
    </p>
    <pre>// Wrong: exits immediately with "stdin is not a terminal"
spawn('codex', ['--dangerously-bypass-approvals-and-sandbox'], {
  stdio: ['pipe', 'pipe', 'pipe']
})

// Right: use a pseudoterminal
const pty = spawn('codex', ['--dangerously-bypass-approvals-and-sandbox'], {
  pty: true
})</pre>

    <h2>The Debugging Loop</h2>
    <p>
      What made this expensive wasn't any single failure — it was the loop. Launch 8 agents, watch all 8 fail in two seconds, read the exit codes, form a hypothesis, update the invocation, launch 8 more agents, watch all 8 fail in two seconds again with a slightly different error. Repeat.
    </p>
    <p>
      Each iteration takes maybe 30 seconds. But you're staring at 8 simultaneous failures and trying to decide whether the problem is the same across all of them or whether different agents are failing for different reasons. When every process exits with the same code it's probably one root cause. When they exit with different codes you might have multiple problems layered on top of each other.
    </p>
    <p>
      The actual debugging wasn't hard once I had the right signal. Getting the right signal required reducing the problem: launch one agent, get its error, fix it, confirm one agent works, then fan back out to eight. Running a broken orchestration at scale just gives you eight copies of the same confusion.
    </p>

    <h2>The Meta-Lesson</h2>
    <p>
      Autonomous agent orchestration has a lot of sharp edges in the plumbing before the actual work starts. The architecture can be sound — the task decomposition, the parallelism model, the result aggregation — and you still get no output because a process spawning flag is wrong.
    </p>
    <p>
      This is different from application-layer bugs. Application bugs usually give you a stack trace or a meaningful error message. Process invocation bugs give you exit code 143 and silence. The feedback loop is harsh because the process is gone before it can tell you anything useful.
    </p>
    <p>
      The checklist I'd add to any agent orchestration project before the first real run:
    </p>
    <p>
      <strong>Verify the invocation mode.</strong> Does the tool you're spawning expect a TTY? Does it have a scriptable/non-interactive flag? Test it manually with the exact same flags your orchestrator will use, from a non-interactive context.
    </p>
    <p>
      <strong>Reduce before scaling.</strong> Make one agent work correctly end-to-end before launching eight. Parallelism amplifies problems. It doesn't surface root causes — it buries them in noise.
    </p>
    <p>
      <strong>Capture stderr separately.</strong> Exit code 143 without stderr is nearly useless. Configure your process spawning to capture stderr from the start so when something goes wrong you have signal to work with.
    </p>
    <p>
      <strong>Check the PTY requirement early.</strong> Some tools (Codex) always need a PTY. Some tools (Claude with <code>--print</code>) don't. Know which category each tool falls into before you build the integration layer.
    </p>
    <p>
      The agents eventually ran. All 8, in parallel, completing their tasks in under 90 seconds of wall time. The work itself was fine. The 40 minutes before that were process plumbing and flag archaeology.
    </p>
    <p>
      That ratio — 40 minutes of substrate, 90 seconds of value — is the honest version of what autonomous agent orchestration looks like when you're building it from scratch.
    </p>

  </article>

  <div class="nav">
    <a href="/posts/2026-02-22-the-scope-gap.html">← 006: The Scope Gap</a>
    <a href="/posts/2026-02-24-memory-problem.html">008: The Memory Problem →</a>
  </div>
</main>

<footer>
  CLANKA &nbsp;·&nbsp; <a href="/">clankamode.github.io</a>
</footer>

</body>
</html>
